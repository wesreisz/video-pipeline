name: Deploy Video Pipeline

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
    types: [ closed ]
  workflow_dispatch: # Allow manual trigger

env:
  # Global environment variables
  AWS_REGION: ${{ secrets.AWS_REGION || 'us-east-1' }}
  TF_VAR_openai_api_key: ${{ secrets.OPENAI_API_KEY }}
  TF_VAR_pinecone_api_key: ${{ secrets.PINECONE_API_KEY }}
  TF_VAR_certificate_domain: ${{ secrets.CERTIFICATE_DOMAIN || 'icaet-dev.wesleyreisz.com' }}

jobs:
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master' || (github.event.pull_request.merged == true && (github.event.pull_request.base.ref == 'main' || github.event.pull_request.base.ref == 'master'))
    
    strategy:
      matrix:
        module: [transcribe-module, chunking-module, embedding-module, question-module]
      fail-fast: false  # Continue testing other modules even if one fails
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Test ${{ matrix.module }}
      working-directory: modules/${{ matrix.module }}
      env:
        # Set AWS region for tests that might need boto3
        AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
        AWS_REGION: ${{ env.AWS_REGION }}
        # Set dummy AWS credentials for testing (many AWS SDKs require these to be set)
        AWS_ACCESS_KEY_ID: dummy-access-key-for-testing
        AWS_SECRET_ACCESS_KEY: dummy-secret-key-for-testing
      run: |
        echo "ðŸ§ª Testing ${{ matrix.module }}..."
        
        # Create virtual environment
        python -m venv .venv
        source .venv/bin/activate
        
        # Install dependencies
        pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r dev-requirements.txt
        
        # Install test requirements if exists
        if [ -f requirements-test.txt ]; then
          pip install -r requirements-test.txt
        fi
        
        # Run tests based on module
        if [ "${{ matrix.module }}" = "transcribe-module" ]; then
          python -m pytest -xvs tests/ --ignore=tests/integration --junit-xml=pytest.xml
        elif [ "${{ matrix.module }}" = "chunking-module" ]; then
          python -m pytest tests/ -v --cov=src.handlers --cov-report=term-missing --junit-xml=pytest.xml
        elif [ "${{ matrix.module }}" = "embedding-module" ]; then
          python -m pytest tests/unit/ -v --junit-xml=pytest.xml
        elif [ "${{ matrix.module }}" = "question-module" ]; then
          python -m pytest tests/unit/ -v --junit-xml=pytest-unit.xml
          python -m pytest tests/integration -v --junit-xml=pytest-integration.xml
        fi
    
    - name: Upload test results for ${{ matrix.module }}
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ matrix.module }}
        path: modules/${{ matrix.module }}/pytest*.xml
        retention-days: 30

  build:
    name: Build Lambda Packages
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y zip unzip
    
    - name: Build Lambda Layers
      run: |
        echo "ðŸ—ï¸ Building Lambda layers..."
        
        # Build embedding module layer
        cd modules/embedding-module/layer
        chmod +x 1-install.sh 2-package.sh
        ./1-install.sh && ./2-package.sh
        
        # Build question module layer  
        cd ../../question-module/layer
        chmod +x 1-install.sh 2-package.sh
        ./1-install.sh && ./2-package.sh
    
    - name: Package Lambda Functions
      run: |
        echo "ðŸ“¦ Packaging Lambda functions..."
        mkdir -p infra/build
        
        # Package each module
        zip -r infra/build/transcribe_lambda.zip modules/transcribe-module/src/
        zip -r infra/build/chunking_lambda.zip modules/chunking-module/src/
        zip -r infra/build/embedding_lambda.zip modules/embedding-module/src/
        zip -r infra/build/question_lambda.zip modules/question-module/src/
        
        echo "âœ… Lambda packages created:"
        ls -la infra/build/
    
    - name: Upload Lambda packages
      uses: actions/upload-artifact@v4
      with:
        name: lambda-packages
        path: |
          infra/build/
          modules/*/layer/layer_content.zip
        retention-days: 30

  deploy:
    name: Deploy Infrastructure
    runs-on: ubuntu-latest
    needs: [test, build]
    
    permissions:
      contents: read
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Download Lambda packages
      uses: actions/download-artifact@v4
      with:
        name: lambda-packages
        path: .
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ~1.5
        terraform_wrapper: false
    
    - name: Verify AWS Connection
      run: |
        echo "ðŸ” Verifying AWS connection..."
        aws sts get-caller-identity
        aws s3 ls || echo "S3 access check completed"
    
    - name: Terraform Init
      working-directory: infra/environments/dev
      run: |
        echo "ðŸš€ Initializing Terraform..."
        terraform init
    
    - name: Terraform Plan
      working-directory: infra/environments/dev
      run: |
        echo "ðŸ“‹ Creating Terraform plan..."
        terraform plan -out=tfplan
    
    - name: Terraform Apply
      working-directory: infra/environments/dev
      run: |
        echo "ðŸš¢ Applying Terraform plan..."
        terraform apply "tfplan"
    
    - name: Wait for Resources
      working-directory: infra/environments/dev
      run: |
        echo "â³ Waiting for AWS resources to be ready..."
        
        max_attempts=12
        wait_time=10
        attempt=1
        
        while [ $attempt -le $max_attempts ]; do
          echo "Attempt $attempt of $max_attempts: Checking resource readiness..."
          
          # Check Lambda functions
          transcribe_function=$(terraform output -raw transcribe_lambda_function_name)
          chunking_function=$(terraform output -raw chunking_lambda_function_name)
          embedding_function=$(terraform output -raw embedding_lambda_function_name)
          
          all_ready=true
          for func in "$transcribe_function" "$chunking_function" "$embedding_function"; do
            if ! aws lambda get-function --function-name "$func" --query 'Configuration.State' | grep -q "Active"; then
              all_ready=false
              break
            fi
          done
          
          # Check Step Functions
          sfn_arn=$(terraform output -raw sfn_state_machine_arn)
          if ! aws stepfunctions describe-state-machine --state-machine-arn "$sfn_arn" --query 'status' --output text | grep -q "ACTIVE"; then
            all_ready=false
          fi
          
          if [ "$all_ready" = true ]; then
            echo "âœ… All AWS resources are ready!"
            break
          fi
          
          echo "Resources not ready yet. Waiting $wait_time seconds..."
          sleep $wait_time
          attempt=$((attempt + 1))
        done
        
        if [ $attempt -gt $max_attempts ]; then
          echo "âŒ Timeout waiting for resources to be ready"
          exit 1
        fi
    
    - name: Deploy Access List
      working-directory: infra/environments/dev
      run: |
        echo "ðŸ“‹ Deploying access list..."
        access_list_bucket=$(terraform output -raw access_list_bucket_name)
        
        if ! aws s3api head-object --bucket "$access_list_bucket" --key "access.csv" 2>/dev/null; then
          if [ -f "../../../access.csv" ]; then
            aws s3 cp "../../../access.csv" "s3://$access_list_bucket/access.csv"
            echo "âœ… Uploaded access.csv from project root"
          elif [ -f "../../../modules/question-module/access-list/access.csv" ]; then
            aws s3 cp "../../../modules/question-module/access-list/access.csv" "s3://$access_list_bucket/access.csv"
            echo "âœ… Uploaded default access.csv"
          else
            echo "âš ï¸ No access.csv found"
          fi
        else
          echo "âœ… access.csv already exists"
        fi
    
    - name: Upload Terraform State
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: terraform-state
        path: |
          infra/environments/dev/terraform.tfstate
          infra/environments/dev/.terraform/
          infra/environments/dev/tfplan
        retention-days: 90

  test-e2e:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: deploy
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ~1.5
        terraform_wrapper: false
    
    - name: Download Terraform State
      uses: actions/download-artifact@v4
      with:
        name: terraform-state
        path: infra/environments/dev/
    
    - name: Debug Terraform Setup
      working-directory: infra/environments/dev
      run: |
        echo "ðŸ” Debugging Terraform setup..."
        pwd
        echo "Contents of current directory:"
        ls -la
        echo "Checking if terraform.tfstate exists:"
        ls -la terraform.tfstate || echo "terraform.tfstate not found"
        echo "Checking Terraform version:"
        terraform version
        echo "Initializing Terraform..."
        terraform init
        echo "Listing all Terraform outputs:"
        terraform output || echo "Failed to get outputs - checking why..."
        echo "Checking state file content:"
        terraform show -json | jq '.values.outputs | keys' || echo "Failed to parse state"
    
    - name: Install E2E Test Dependencies
      working-directory: tests/e2e
      run: |
        pip install -r requirements.txt
    
    - name: Get API Endpoint (Fallback)
      id: get-endpoint
      run: |
        echo "ðŸ” Getting API Gateway endpoint..."
        
        # Try Terraform output first
        cd infra/environments/dev
        API_ENDPOINT=""
        if terraform output question_api_endpoint 2>/dev/null; then
          API_ENDPOINT=$(terraform output -raw question_api_endpoint)
          echo "âœ… Got endpoint from Terraform: $API_ENDPOINT"
        else
          echo "âš ï¸ Terraform output failed, trying AWS CLI fallback..."
          
          # Get API Gateway ID from AWS
          API_ID=$(aws apigateway get-rest-apis --query "items[?name=='dev_question_api'].id" --output text)
          
          if [ -n "$API_ID" ] && [ "$API_ID" != "None" ]; then
            API_ENDPOINT="https://${API_ID}.execute-api.us-east-1.amazonaws.com/dev/query"
            echo "âœ… Built endpoint from AWS CLI: $API_ENDPOINT"
          else
            echo "âŒ Could not determine API endpoint"
            exit 1
          fi
        fi
        
        # Export for E2E test
        echo "QUESTION_API_ENDPOINT=$API_ENDPOINT" >> $GITHUB_ENV
        echo "endpoint=$API_ENDPOINT" >> $GITHUB_OUTPUT
    
    - name: Run End-to-End Tests
      working-directory: tests/e2e
      run: |
        echo "ðŸ”„ Running end-to-end tests..."
        chmod +x run_e2e_test.sh
        ./run_e2e_test.sh --cleanup
    
    - name: Upload E2E Test Results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: e2e-test-results
        path: tests/e2e/
        retention-days: 30

  summary:
    name: Deployment Summary
    runs-on: ubuntu-latest
    needs: [test, build, deploy, test-e2e]
    if: always()
    
    steps:
    - name: Create Deployment Summary
      run: |
        cat >> $GITHUB_STEP_SUMMARY << 'EOF'
        # ðŸš€ Video Pipeline Deployment Summary
        
        ## Results
        - **Tests**: ${{ needs.test.result }}
        - **Build**: ${{ needs.build.result }}  
        - **Deploy**: ${{ needs.deploy.result }}
        - **E2E Tests**: ${{ needs.test-e2e.result }}
        
        ## Modules Tested
        - âœ… Transcribe Module
        - âœ… Chunking Module  
        - âœ… Embedding Module
        - âœ… Question Module
        
        ## Infrastructure Deployed
        - ðŸª£ S3 Buckets (media, transcription, access-list, cloudtrail)
        - ðŸ”„ Lambda Functions (4 microservices + layers)
        - ðŸŒŠ Step Functions Workflow
        - ðŸ“¡ EventBridge Rules
        - ðŸ”‘ Secrets Manager
        - ðŸ” KMS Keys
        - ðŸ“Š CloudWatch Logs
        - ðŸŒ API Gateway
        
        EOF
    
    - name: Notify on Complete Success
      if: needs.test.result == 'success' && needs.build.result == 'success' && needs.deploy.result == 'success' && needs.test-e2e.result == 'success'
      run: |
        echo "ðŸŽ‰ Complete pipeline success! All components deployed and tested."
    
    - name: Notify on Partial Failure
      if: contains(needs.*.result, 'failure')
      run: |
        echo "âš ï¸ Pipeline completed with some failures. Check individual job results above."
        exit 1 