---
description: testing framework for the project
globs: 
alwaysApply: false
---
# Pytest Testing Standards

## Overview

This project uses pytest as its exclusive testing framework. All test files must be compatible with pytest discovery and execution patterns.

## Naming Conventions

- All test files must follow this pattern:
  - `test_*.py`
- All test functions within these files must be prefixed with `test_`
- All test classes must be prefixed with `Test`

## Test Directory Structure

- Unit tests should be placed in a `tests/unit/` directory at the same level as the module they're testing
- Integration tests should be placed in `tests/integration/` directory
- End-to-end tests are located in the `tests/e2e/` directory at the project root
- Tests that require infrastructure should be placed in `tests/infra/`

## Test Execution

- All tests must be run using pytest
- Use the following command pattern:
  ```bash
  pytest [options] [path_to_tests]
  ```
- Common options:
  - `-v`: verbose output
  - `-xvs`: exit on first failure, verbose, no capture
  - `--cov=<module>`: run coverage on specified module
  - `--cov-report=term-missing`: show missing coverage lines
- To run specific test types:
  ```bash
  # Run e2e tests
  pytest tests/e2e
  
  # Run unit tests only (excluding integration and e2e)
  pytest tests/unit/ -v
  
  # Run with coverage
  pytest tests/unit/ -v --cov=src.handlers --cov-report=term-missing
  ```

## Testing Layers and Strategy

### Unit Tests
- **Scope**: Test individual functions and classes in isolation
- **Location**: `tests/unit/`
- **Mocking**: Mock all external dependencies (AWS services, HTTP calls)
- **Coverage Target**: Maintain >80% code coverage
- **Speed**: Should run in under 10 seconds per module

### Integration Tests
- **Scope**: Test service interactions with mocked AWS services
- **Location**: `tests/integration/`
- **Tools**: Use `moto` for AWS service mocking
- **Focus**: Test data flow and service integration patterns

### End-to-End Tests
- **Scope**: Test complete pipeline with real AWS resources
- **Location**: `tests/e2e/` (project root)
- **Purpose**: Validate full system workflows
- **Execution**: Run after deployment to verify system health

## Fixtures and Configuration

### conftest.py Requirements
Each module's `tests/conftest.py` MUST include:
```python
import os
import sys
import pytest

# Add the src directory to the Python path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../src')))
```

### Standard Fixtures
- **AWS Credentials**: Mock AWS credentials for testing
- **S3 Events**: Standardized S3 event fixtures
- **Response Objects**: Mock AWS service responses
- **Test Data**: Sample transcriptions, chunks, and metadata

### Shared Fixtures
- Place module-specific fixtures in `conftest.py` files
- Use parametrized tests where appropriate using `@pytest.mark.parametrize`
- Create reusable fixtures for common test data patterns

## AWS Testing Patterns

### Mocking AWS Services
```python
import boto3
from moto import mock_s3, mock_sqs, mock_secretsmanager

@mock_s3
@mock_sqs
def test_lambda_handler():
    # Test implementation with mocked AWS services
    pass
```

### Testing EventBridge Format
All event handling tests must validate EventBridge format:
```python
def test_eventbridge_format():
    event = {
        'detail': {
            'requestParameters': {
                'bucketName': 'test-bucket',
                'key': 'test-file.mp3'
            }
        }
    }
    # Test event processing
```

### Lambda Handler Testing
- Test both EventBridge and direct S3 event formats
- Validate response format with statusCode and detail structure
- Test error handling and exception propagation

## Coverage Requirements

- **Minimum Coverage**: 80% code coverage for all modules
- **Handler Coverage**: 100% coverage for Lambda handlers
- **Service Coverage**: >90% coverage for service layer
- **Exclusions**: Only exclude error handling and logging statements

## CI Integration

- CI pipelines must execute tests using pytest
- Test reports should be generated in JUnit XML format using `--junitxml=report.xml`
- Coverage reports should be generated using `--cov-report=xml`
- Failed tests should fail the CI pipeline

## Best Practices

### Test Independence
- Keep tests independent and idempotent
- Use fresh mocks for each test
- Clean up test data and state

### Test Organization
- Group tests by functionality
- Use descriptive test names that explain the scenario
- Follow Arrange-Act-Assert pattern

### Mocking Strategy
- Mock external services (AWS, OpenAI, Pinecone)
- Don't mock the code under test
- Use real objects for data structures and models

### Error Testing
- Test both success and failure scenarios
- Validate error messages and status codes
- Test edge cases and boundary conditions

## Dependencies

Add test dependencies to `dev-requirements.txt`:
```
pytest>=7.0.0
pytest-cov>=4.0.0
pytest-mock>=3.10.0
pytest-env>=1.0.0
pytest-xdist>=3.3.0  # For parallel test execution
moto>=4.0.0          # AWS service mocking
boto3>=1.34.0        # AWS SDK
```

## Test Markers

Use pytest markers for test categorization:
```python
@pytest.mark.unit
def test_unit_function():
    pass

@pytest.mark.integration
def test_integration_flow():
    pass

@pytest.mark.slow
def test_long_running_process():
    pass
```

Run specific test categories:
```bash
# Run only unit tests
pytest -m unit

# Skip slow tests
pytest -m "not slow"
```